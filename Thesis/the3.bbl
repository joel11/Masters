% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{BailyPBO}
\BIBentryALTinterwordspacing
D.~H. Bailey, J.~Borwein, M.~López~de Prado, and Q.~J. Zhu, ``The probability
  of backtest overfitting,'' \emph{Journal of Computational Finance}, vol.~20,
  pp. 39--69, 4 2017. [Online]. Available:
  \url{https://www.davidhbailey.com/dhbpapers/backtest-prob.pdf}
\BIBentrySTDinterwordspacing

\bibitem{Murphy}
J.~Murphy, ``Technical analysis of financial markets,'' 01 1999.

\bibitem{Griffioen}
G.~Griffioen, ``Technical analysis in financial markets,'' \emph{SSRN
  Electronic Journal}, 03 2003.

\bibitem{Kahn}
M.~N. Kahn, \emph{Technical Analysis Plain and Simple: Charting the Markets in
  Your Language}.\hskip 1em plus 0.5em minus 0.4em\relax Financial Times Press,
  2006.

\bibitem{Schwager}
J.~D. Schwager, \emph{Getting Started in Technical Analysis}.\hskip 1em plus
  0.5em minus 0.4em\relax Wiley, 1999.

\bibitem{Johnson}
N.~Johnson, G.~Zhao, E.~Hunsader, H.~Qi, N.~Johnson, J.~Meng, and B.~Tivnan,
  ``Abrupt rise of new machine ecology beyond human response time,''
  \emph{Scientific reports}, vol.~3, p. 2627, 09 2013.

\bibitem{Arthur}
\BIBentryALTinterwordspacing
B.~Arthur, ``Complexity in economics and financial markets,''
  \emph{Complexity}, vol.~1, pp. 20--25, 10 1995. [Online]. Available:
  \url{https://onlinelibrary.wiley.com/doi/epdf/10.1002/cplx.6130010106}
\BIBentrySTDinterwordspacing

\bibitem{Crutchfield}
J.~Crutchfield, ``Between order and chaos,'' \emph{Nature Physics}, vol.~9, pp.
  382--382, 06 2013.

\bibitem{Packard}
N.~Packard, J.~Crutchfield, and R.~Shaw, ``Geometry from a time series,''
  \emph{Phys. Rev. Lett.}, vol.~45, p. 712, 09 1980.

\bibitem{Takens}
F.~Takens, ``Detecting strange attractors in turbulence,'' \emph{Dynamical
  Systems and Turbulance serial Lecture notes in Mathematics}, vol. 898, 01
  1981.

\bibitem{Skabar}
A.~Skabar and I.~Cloete, ``Neural networks, financial trading and the efficient
  markets hypothesis,'' \emph{ACSC '02: Proceedings of the Twenty-fifth
  Australasian Conference on Computer Science}, vol.~4, 02 2002.

\bibitem{Schmidhuber}
J.~Schmidhuber, ``Deep learning in neural networks: An overview,'' \emph{Neural
  Networks}, vol.~61, pp. 85--117, 01 2015.

\bibitem{Ivakhnenko}
A.~Ivakhnenko, ``Polynomial theory of complex systems. ieee trans syst man
  cybern,'' \emph{Systems, Man and Cybernetics, IEEE Transactions on}, vol.~1,
  pp. 364 -- 378, 11 1971.

\bibitem{Werbos}
P.~Werbos and P.~John, ``Beyond regression : new tools for prediction and
  analysis in the behavioral sciences /,'' 01 1974.

\bibitem{Siegelmann}
H.~Siegelmann, ``Theoretical foundations of recurrent neural networks,'' 11
  2019.

\bibitem{Hochreiter}
S.~Hochreiter and J.~Schmidhuber, ``Long short-term memory,'' \emph{Neural
  computation}, vol.~9, pp. 1735--80, 12 1997.

\bibitem{Minksy}
M.~Minsky and S.~Papert, \emph{Perceptrons: An Introduction to Computational
  Geometry}, 01 2017.

\bibitem{LeCun2}
Y.~Lecun, ``A theoretical framework for back-propagation,'' 01 1992.

\bibitem{Werbos2}
P.~Werbos, \emph{Applications of advances in nonlinear sensitivity analysis},
  01 1970, vol.~38, pp. 762--770.

\bibitem{Rumelhart}
D.~Rumelhart, G.~Hinton, and W.~RJ, ``Learning internal representations by
  error propagation,'' \emph{Parallel Distributed Processing: Explorations in
  the Microstructure of Cognition}, vol.~1, 07 1986.

\bibitem{LeCun3}
L.~Cun, Y.~Boser, B.~Denker, D.~Henderson, R.~Howard, W.~Hubbard, and
  L.~Jackel, ``Back-propagation applied to handwritten zip-code recognition,''
  \emph{Neural Computation - NECO}, 01 1992.

\bibitem{Pascanu}
R.~Pascanu, T.~Mikolov, and Y.~Bengio, ``On the difficulty of training
  recurrent neural networks,'' \emph{30th International Conference on Machine
  Learning, ICML 2013}, 11 2012.

\bibitem{LeCun4}
Y.~LeCun, Y.~Bengio, and G.~Hinton, ``Deep learning,'' \emph{Nature}, vol. 521,
  pp. 436--44, 05 2015.

\bibitem{Dauphin}
Y.~Dauphin, R.~Pascanu, C.~Gulcehre, K.~Cho, S.~Ganguli, and Y.~Bengio,
  ``Identifying and attacking the saddle point problem in high-dimensional
  non-convex optimization,'' \emph{NIPS}, vol.~27, 06 2014.

\bibitem{Ge}
\BIBentryALTinterwordspacing
R.~Ge, F.~Huang, C.~Jin, and Y.~Yuan, ``Escaping from saddle points --- online
  stochastic gradient for tensor decomposition,'' 03 2015. [Online]. Available:
  \url{http://proceedings.mlr.press/v40/Ge15.pdf}
\BIBentrySTDinterwordspacing

\bibitem{Hornik}
K.~Hornik, ``Multilayer feed-forward networks are universal approximators,''
  \emph{Neural Networks}, vol.~2, pp. 359--366, 1989.

\bibitem{Wu}
H.~Wu, ``Global stability analysis of a general class of discontinuous neural
  networks with linear growth activation functions,'' \emph{Inf. Sci.}, vol.
  179, pp. 3432--3441, 09 2009.

\bibitem{Glorot}
X.~Glorot and Y.~Bengio, ``Understanding the difficulty of training deep
  feedforward neural networks,'' \emph{Journal of Machine Learning Research -
  Proceedings Track}, vol.~9, pp. 249--256, 01 2010.

\bibitem{Glorot2}
X.~Glorot, A.~Bordes, and Y.~Bengio, ``Deep sparse rectifier neural networks,''
  \emph{Proceedings of the 14th International Conference on Artificial
  Intelligence and Statisitics (AISTATS) 2011}, vol.~15, pp. 315--323, 01 2011.

\bibitem{Bengio1}
Y.~Bengio, P.~Lamblin, D.~Popovici, and H.~Larochelle, ``Greedy layer-wise
  training of deep networks,'' \emph{Adv. Neural Inf. Process. Syst.}, vol.~19,
  pp. 153--160, 01 2007.

\bibitem{Hinton1}
G.~Hinton, S.~Osindero, and Y.-W. Teh, ``A fast learning algorithm for deep
  belief nets,'' \emph{Neural computation}, vol.~18, pp. 1527--54, 08 2006.

\bibitem{Ranzato1}
M.~Ranzato, C.~Poultney, S.~Chopra, and Y.~Lecun, ``Efficient learning of
  sparse representations with an energy-based model,'' 01 2006.

\bibitem{Hinton2}
G.~Hinton and R.~Salakhutdinov, ``Reducing the dimensionality of data with
  neural networks,'' \emph{Science (New York, N.Y.)}, vol. 313, pp. 504--7, 08
  2006.

\bibitem{LeRoux}
N.~Roux and Y.~Bengio, ``1 representational power of restricted boltzmann
  machines and deep belief networks,'' \emph{Neural computation}, vol.~20, pp.
  1631--49, 07 2008.

\bibitem{Bengio2}
\BIBentryALTinterwordspacing
Y.~Bengio and S.~Bengio, ``Modeling high-dimensional discrete data with
  multi-layer neural networks,'' 02 2001. [Online]. Available:
  \url{http://papers.nips.cc/paper/1679-modeling-high-dimensional-discrete-data-with-multi-layer-neural-networks.pdf}
\BIBentrySTDinterwordspacing

\bibitem{Sermanet}
P.~Sermanet, K.~Kavukcuoglu, S.~Chintala, and Y.~Lecun, ``Pedestrian detection
  with unsupervised multi-stage feature learning,'' \emph{Proceedings / CVPR,
  IEEE Computer Society Conference on Computer Vision and Pattern Recognition.
  IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  12 2012.

\bibitem{ImageNet}
A.~Krizhevsky, I.~Sutskever, and G.~Hinton, ``Imagenet classification with deep
  convolutional neural networks,'' \emph{Neural Information Processing
  Systems}, vol.~25, 01 2012.

\bibitem{WaveNet}
A.~oord, S.~Dieleman, H.~Zen, K.~Simonyan, O.~Vinyals, A.~Graves,
  N.~Kalchbrenner, A.~Senior, and K.~Kavukcuoglu, ``Wavenet: A generative model
  for raw audio,'' 09 2016.

\bibitem{Ciresan}
D.~Cireşan, U.~Meier, L.~Gambardella, and J.~Schmidhuber, ``Deep, big, simple
  neural nets for handwritten digit recognition,'' \emph{Neural computation},
  vol.~22, pp. 3207--20, 12 2010.

\bibitem{Bengio3}
Y.~Bengio, A.~Courville, and P.~Vincent, ``Representation learning: A review
  and new perspectives,'' \emph{IEEE transactions on pattern analysis and
  machine intelligence}, vol.~35, pp. 1798--1828, 08 2013.

\bibitem{He}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Delving deep into rectifiers: Surpassing
  human-level performance on imagenet classification,'' \emph{IEEE
  International Conference on Computer Vision (ICCV 2015)}, vol. 1502, 02 2015.

\bibitem{Schaefer}
R.~Schaefer, ``Subset selection in regression,'' \emph{Technometrics}, vol.~34,
  03 2012.

\bibitem{Donoho}
D.~Donoho, ``High-dimensional data analysis: The curses and blessings of
  dimensionality,'' \emph{AMS Math Challenges Lecture}, pp. 1--32, 01 2000.

\bibitem{Fan1}
J.~Fan and R.~Li, ``Statistical challenges with high dimensionality: Feature
  selection in knowledge discovery,'' \emph{Proc. Madrid Int. Congress of
  Mathematicians}, vol.~3, 03 2006.

\bibitem{Fan2}
J.~Fan and Y.~Fan, ``High dimensional classification using features annealed
  independence rules,'' \emph{Annals of statistics}, vol.~36, pp. 2605--2637,
  02 2008.

\bibitem{Fama}
E.~Fama, ``The behavior of stock market price,'' \emph{Journal of Business - J
  BUS}, vol.~38, 01 1965.

\bibitem{Langkvist}
M.~Längkvist, L.~Karlsson, and A.~Loutfi, ``A review of unsupervised feature
  learning and deep learning for time-series modeling,'' \emph{Pattern
  Recognition Letters}, vol.~42, 06 2014.

\bibitem{Hinton3}
G.~Hinton, ``Article training products of experts by minimizing contrastive
  divergence,'' \emph{Neural computation}, vol.~14, pp. 1771--800, 09 2002.

\bibitem{Vincent}
P.~Vincent, H.~Larochelle, I.~Lajoie, Y.~Bengio, and P.-A. Manzagol, ``Stacked
  denoising autoencoders: Learning useful representations in a deep network
  with a local denoising criterion,'' \emph{Journal of Machine Learning
  Research}, vol.~11, pp. 3371--3408, 12 2010.

\bibitem{Erhan}
D.~Erhan, Y.~Bengio, A.~Courville, P.-A. Manzagol, P.~Vincent, and S.~Bengio,
  ``Why does unsupervised pre-training help deep learning?'' \emph{Journal of
  Machine Learning Research}, vol.~11, pp. 625--660, 02 2010.

\bibitem{Lv}
L.~Yisheng, Y.~Duan, W.~Kang, Z.~Li, and F.-Y. Wang, ``Traffic flow prediction
  with big data: A deep learning approach,'' \emph{IEEE Transactions on
  Intelligent Transportation Systems}, vol.~16, pp. 865--873, 01 2014.

\bibitem{Takeuchi}
L.~Takeuchi, ``Applying deep learning to enhance momentum trading strategies in
  stocks,'' 2013.

\bibitem{Zhao}
Y.~Zhao, J.~Li, and L.~Yu, ``A deep learning ensemble approach for crude oil
  price forecasting,'' \emph{Energy Economics}, vol.~66, 06 2017.

\bibitem{Troiano}
L.~Troiano, E.~Villa, and P.~Kriplani, ``On feature reduction using deep
  learning for trend prediction in finance,'' 04 2017.

\bibitem{Bao}
W.~Bao, J.~Yue, and Y.~Rao, ``A deep learning framework for financial time
  series using stacked autoencoders and long-short term memory,'' \emph{PLoS
  ONE}, vol.~12, 07 2017.

\bibitem{Hsu}
D.~Hsu, ``Time series compression based on adaptive piecewise recurrent
  autoencoder,'' 07 2017.

\bibitem{Albers}
\BIBentryALTinterwordspacing
S.~Albers, ``Online algorithms: a survey,'' \emph{Mathematical Programming},
  vol.~97, pp. 3--26, 05 2003. [Online]. Available:
  \url{https://link.springer.com/content/pdf/10.1007%2Fs10107-003-0436-0.pdf}
\BIBentrySTDinterwordspacing

\bibitem{Bottou}
L.~Bottou and Y.~Lecun, ``Large scale online learning.'' \emph{Advances in
  Neural Information Processing Systems 16}, 03 2004.

\bibitem{LeCun}
Y.~Lecun, L.~Bottou, G.~Orr, and K.-R. Müller, \emph{Efficient BackProp}, 01
  1998, vol. 1524, pp. 546--546.

\bibitem{Bottou2}
L.~Bottou and N.~Murata, \emph{Stochastic Approximations and Efficient
  Learning, The Handbook of Brain Theory and Neural Networks}, 2nd~ed.\hskip
  1em plus 0.5em minus 0.4em\relax The MIT Press, 2019.

\bibitem{Shalev}
S.~Shalev-Shwartz, Y.~Singer, N.~Srebro, and A.~Cotter, ``Pegasos: Primal
  estimated sub-gradient solver for svm,'' \emph{Math. Program.}, vol. 127, pp.
  3--30, 03 2011.

\bibitem{Zhang}
T.~Zhang, ``Solving large scale linear prediction problems using stochastic
  gradient descent algorithms,'' 01 2004.

\bibitem{Tseng}
P.~Tseng, ``An incremental gradient(-projection) method with momentum term and
  adaptive stepsize rule,'' \emph{SIAM Journal on Optimization}, vol.~8, 04
  1999.

\bibitem{Bartlett}
P.~Bartlett, E.~Hazan, and A.~Rakhlin, ``Adaptive online gradient descent.''
  \emph{Advances in Neural Information Processing Systems 20 - Proceedings of
  the 2007 Conference}, 01 2007.

\bibitem{Langford}
J.~Langford, L.~Li, and T.~Zhang, ``Sparse online learning via truncated
  gradient,'' \emph{Journal of Machine Learning Research}, vol.~10, 07 2008.

\bibitem{Duchi}
J.~Duchi, E.~Hazan, and Y.~Singer, ``Adaptive subgradient methods for online
  learning and stochastic optimization,'' \emph{Journal of Machine Learning
  Research}, vol.~12, pp. 2121--2159, 07 2011.

\bibitem{Zeiler}
M.~Zeiler, ``Adadelta: An adaptive learning rate method,'' vol. 1212, 12 2012.

\bibitem{Hinton4}
G.~Hinton, N.~Srivastava, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov,
  ``Improving neural networks by preventing co-adaptation of feature
  detectors,'' \emph{arXiv preprint}, vol. arXiv, 07 2012.

\bibitem{Goodfellow}
I.~Goodfellow, D.~Warde-Farley, M.~Mirza, A.~Courville, and Y.~Bengio, ``Maxout
  networks,'' \emph{30th International Conference on Machine Learning, ICML
  2013}, vol. 1302, 02 2013.

\bibitem{Wang2}
\BIBentryALTinterwordspacing
S.~Wang and C.~Manning, ``Fast dropout training,'' in \emph{Proceedings of the
  30th International Conference on Machine Learning}, ser. Proceedings of
  Machine Learning Research, S.~Dasgupta and D.~McAllester, Eds., vol.~28,
  no.~2.\hskip 1em plus 0.5em minus 0.4em\relax Atlanta, Georgia, USA: PMLR,
  17--19 Jun 2013, pp. 118--126. [Online]. Available:
  \url{http://proceedings.mlr.press/v28/wang13a.html}
\BIBentrySTDinterwordspacing

\bibitem{Smith}
L.~Smith, ``Cyclical learning rates for training neural networks,'' 03 2017,
  pp. 464--472.

\bibitem{Loshchilov}
I.~Loshchilov and F.~Hutter, ``Sgdr: Stochastic gradient descent with warm
  restarts,'' 08 2016.

\bibitem{Ioannidis}
J.~Ioannidis, ``Why most published research findings are false,''
  \emph{CHANCE}, vol.~32, pp. 4--13, 01 2019.

\bibitem{McLean}
R.~Mclean and J.~Pontiff, ``Does academic research destroy stock return
  predictability?'' \emph{The Journal of Finance}, vol.~71, 05 2013.

\bibitem{Schorfheide}
F.~Schorfheide and K.~Wolpin, ``On the use of holdout samples for model
  selection,'' \emph{American Economic Review}, vol. 102, 05 2012.

\bibitem{Prado}
M.~Lopez~de Prado, ``The future of empirical finance,'' \emph{The Journal of
  Portfolio Management}, vol.~41, pp. 140--144, 07 2015.

\bibitem{Weiss}
S.~M. Weiss and C.~A. Kulikowski, \emph{Computer Systems That Learn:
  Classification and Prediction Methods from Statistics, Neural Nets, Machine
  Learning, and Expert Systems}.\hskip 1em plus 0.5em minus 0.4em\relax San
  Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1991.

\bibitem{Hawkins}
D.~Hawkins, ``The problem of overfitting,'' \emph{Journal of chemical
  information and computer sciences}, vol.~44, pp. 1--12, 05 2004.

\bibitem{Hansen}
P.~Hansen, J.~Nason, and A.~Lunde, ``The model confidence set,''
  \emph{Econometrica}, vol.~79, pp. 453--497, 03 2010.

\bibitem{Aparicio}
\BIBentryALTinterwordspacing
D.~Aparicio and M.~Lopez~de Prado, ``How hard is it to pick the right model?
  mcs and backtest overfitting,'' \emph{Algorithmic Finance}, vol.~7, pp.
  53--61, 01 2018. [Online]. Available: \url{https://ssrn.com/abstract=3044740}
\BIBentrySTDinterwordspacing

\bibitem{Lo}
A.~Lo, ``The statistics of sharpe ratios,'' \emph{Financial Analysts Journal},
  vol.~58, 02 2003.

\bibitem{BaileyBTL}
\BIBentryALTinterwordspacing
D.~H. Bailey, J.~Borwein, M.~Lopez~de Prado, and Q.~J. Zhu,
  ``Pseudo-mathematics and financial charlatanism: The effects of backtest
  overfitting on out-of-sample performance,'' \emph{Notices of the American
  Mathematical Society}, vol.~61, pp. 458--471, 4 2014. [Online]. Available:
  \url{https://ssrn.com/abstract=2308659}
\BIBentrySTDinterwordspacing

\bibitem{BaileySharpe}
D.~Bailey and M.~Lopez~de Prado, ``The deflated sharpe ratio: Correcting for
  selection bias, backtest overfitting, and non-normality,'' \emph{The Journal
  of Portfolio Management}, vol.~40, pp. 94--107, 09 2014.

\bibitem{Hinton5}
G.~Hinton, ``A practical guide to training restricted boltzmann machines[j],''
  \emph{Momentum}, vol.~9, pp. 926--947, 01 2010.

\bibitem{Wilcox}
D.~Wilcox and T.~Gebbie, ``Hierarchical causality in financial economics,''
  \emph{SSRN Electronic Journal}, 08 2014.

\bibitem{Peters}
A.~A. Ole~Peters, \emph{Ergodicity Economics}.\hskip 1em plus 0.5em minus
  0.4em\relax London Mathematical Laboratory, 2018.

\end{thebibliography}
