\BOOKMARK [1][-]{Doc-Start}{List of Figures}{}% 1
\BOOKMARK [1][-]{Doc-Start}{List of Tables}{}% 2
\BOOKMARK [1][-]{section.1}{Introduction}{}% 3
\BOOKMARK [1][-]{section.2}{Literature Review}{}% 4
\BOOKMARK [2][-]{subsection.2.1}{Technical Analysis}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.2}{Neural Networks}{section.2}% 6
\BOOKMARK [3][-]{subsubsection.2.2.1}{Training and Backpropagation}{subsection.2.2}% 7
\BOOKMARK [3][-]{subsubsection.2.2.2}{Activation Functions}{subsection.2.2}% 8
\BOOKMARK [3][-]{subsubsection.2.2.3}{Deep Learning}{subsection.2.2}% 9
\BOOKMARK [3][-]{subsubsection.2.2.4}{Weight Initialization Improvements}{subsection.2.2}% 10
\BOOKMARK [2][-]{subsection.2.3}{Stacked AutoEncoders}{section.2}% 11
\BOOKMARK [3][-]{subsubsection.2.3.1}{High Dimensional Data Reduction}{subsection.2.3}% 12
\BOOKMARK [3][-]{subsubsection.2.3.2}{Deep Belief Networks}{subsection.2.3}% 13
\BOOKMARK [3][-]{subsubsection.2.3.3}{Stacked Denoising AutoEncoders}{subsection.2.3}% 14
\BOOKMARK [3][-]{subsubsection.2.3.4}{Pretraining}{subsection.2.3}% 15
\BOOKMARK [3][-]{subsubsection.2.3.5}{Financial Time Series Applications}{subsection.2.3}% 16
\BOOKMARK [2][-]{subsection.2.4}{Online Learning Algorithms and Gradient Descent}{section.2}% 17
\BOOKMARK [2][-]{subsection.2.5}{Gradient Learning Improvements}{section.2}% 18
\BOOKMARK [3][-]{subsubsection.2.5.1}{Gradient Adjustments and Regularization}{subsection.2.5}% 19
\BOOKMARK [3][-]{subsubsection.2.5.2}{Dropout}{subsection.2.5}% 20
\BOOKMARK [3][-]{subsubsection.2.5.3}{Learning Rate Schedules}{subsection.2.5}% 21
\BOOKMARK [2][-]{subsection.2.6}{Backtesting and Model Validation}{section.2}% 22
\BOOKMARK [3][-]{subsubsection.2.6.1}{Sharpe Ratio Assessment Methodologies}{subsection.2.6}% 23
\BOOKMARK [3][-]{subsubsection.2.6.2}{Generalised Assessment Methodologies}{subsection.2.6}% 24
\BOOKMARK [3][-]{subsubsection.2.6.3}{Test Data Length}{subsection.2.6}% 25
\BOOKMARK [1][-]{section.3}{Data Processing and Generation }{}% 26
\BOOKMARK [2][-]{subsection.3.1}{Data Processing}{section.3}% 27
\BOOKMARK [3][-]{subsubsection.3.1.1}{Log Difference Transformation and Aggregation}{subsection.3.1}% 28
\BOOKMARK [3][-]{subsubsection.3.1.2}{Data Scaling}{subsection.3.1}% 29
\BOOKMARK [3][-]{subsubsection.3.1.3}{Reverse Data Scaling}{subsection.3.1}% 30
\BOOKMARK [3][-]{subsubsection.3.1.4}{Price Reconstruction}{subsection.3.1}% 31
\BOOKMARK [3][-]{subsubsection.3.1.5}{Decorrelation}{subsection.3.1}% 32
\BOOKMARK [2][-]{subsection.3.2}{Synthetic Data Generation}{section.3}% 33
\BOOKMARK [3][-]{subsubsection.3.2.1}{GBM Data Distributions}{subsection.3.2}% 34
\BOOKMARK [2][-]{subsection.3.3}{Price Considerations}{section.3}% 35
\BOOKMARK [1][-]{section.4}{Models and Algorithms}{}% 36
\BOOKMARK [2][-]{subsection.4.1}{Process Overview}{section.4}% 37
\BOOKMARK [2][-]{subsection.4.2}{Feedforward Neural Networks}{section.4}% 38
\BOOKMARK [3][-]{subsubsection.4.2.1}{Notation and Network Representation}{subsection.4.2}% 39
\BOOKMARK [3][-]{subsubsection.4.2.2}{Activation Functions}{subsection.4.2}% 40
\BOOKMARK [4][-]{paragraph.4.2.2.1}{Sigmoid}{subsubsection.4.2.2}% 41
\BOOKMARK [4][-]{paragraph.4.2.2.2}{ReLU}{subsubsection.4.2.2}% 42
\BOOKMARK [4][-]{paragraph.4.2.2.3}{Leaky ReLU}{subsubsection.4.2.2}% 43
\BOOKMARK [4][-]{paragraph.4.2.2.4}{Linear Activation}{subsubsection.4.2.2}% 44
\BOOKMARK [3][-]{subsubsection.4.2.3}{Backpropagation}{subsection.4.2}% 45
\BOOKMARK [3][-]{subsubsection.4.2.4}{Gradient Descent Algorithms}{subsection.4.2}% 46
\BOOKMARK [3][-]{subsubsection.4.2.5}{Regularization}{subsection.4.2}% 47
\BOOKMARK [3][-]{subsubsection.4.2.6}{Learning Rate Schedule}{subsection.4.2}% 48
\BOOKMARK [3][-]{subsubsection.4.2.7}{Dropout}{subsection.4.2}% 49
\BOOKMARK [2][-]{subsection.4.3}{Restricted Boltzmann Machines}{section.4}% 50
\BOOKMARK [3][-]{subsubsection.4.3.1}{RBM Stochastic Descent}{subsection.4.3}% 51
\BOOKMARK [3][-]{subsubsection.4.3.2}{Contrastive Divergence}{subsection.4.3}% 52
\BOOKMARK [3][-]{subsubsection.4.3.3}{CD-1 and SGD}{subsection.4.3}% 53
\BOOKMARK [2][-]{subsection.4.4}{Stacked AutoEncoders}{section.4}% 54
\BOOKMARK [3][-]{subsubsection.4.4.1}{Sigmoid Based Greedy Layerwise SAE Training}{subsection.4.4}% 55
\BOOKMARK [3][-]{subsubsection.4.4.2}{ReLU based SAE Training}{subsection.4.4}% 56
\BOOKMARK [3][-]{subsubsection.4.4.3}{Denoising AutoEncoders}{subsection.4.4}% 57
\BOOKMARK [4][-]{paragraph.4.4.3.1}{Additive Gaussian Noise}{subsubsection.4.4.3}% 58
\BOOKMARK [4][-]{paragraph.4.4.3.2}{Masking Noise}{subsubsection.4.4.3}% 59
\BOOKMARK [2][-]{subsection.4.5}{Variance Based Weight Initializations}{section.4}% 60
\BOOKMARK [3][-]{subsubsection.4.5.1}{Initialization Rationale}{subsection.4.5}% 61
\BOOKMARK [3][-]{subsubsection.4.5.2}{Initializations}{subsection.4.5}% 62
\BOOKMARK [4][-]{paragraph.4.5.2.1}{``Xavier'' Initialization}{subsubsection.4.5.2}% 63
\BOOKMARK [4][-]{paragraph.4.5.2.2}{``He'' Initialization}{subsubsection.4.5.2}% 64
\BOOKMARK [4][-]{paragraph.4.5.2.3}{``He-Adjusted'' Initialization}{subsubsection.4.5.2}% 65
\BOOKMARK [2][-]{subsection.4.6}{Money Management Strategy and Returns}{section.4}% 66
\BOOKMARK [3][-]{subsubsection.4.6.1}{Input Variables}{subsection.4.6}% 67
\BOOKMARK [3][-]{subsubsection.4.6.2}{Calculated Asset Variables}{subsection.4.6}% 68
\BOOKMARK [3][-]{subsubsection.4.6.3}{Calculated Strategy Variables}{subsection.4.6}% 69
\BOOKMARK [2][-]{subsection.4.7}{Combinatorially Symmetric Cross-Validation and Probability of Backtest Overfitting}{section.4}% 70
\BOOKMARK [2][-]{subsection.4.8}{Deflated Sharpe Ratio}{section.4}% 71
\BOOKMARK [3][-]{subsubsection.4.8.1}{Optimal Number of Clusters Algorithm}{subsection.4.8}% 72
\BOOKMARK [3][-]{subsubsection.4.8.2}{Sharpe Ratio Normality and Probabilistic Sharpe Ratio}{subsection.4.8}% 73
\BOOKMARK [3][-]{subsubsection.4.8.3}{False Strategy Theorem}{subsection.4.8}% 74
\BOOKMARK [3][-]{subsubsection.4.8.4}{Deflated Sharpe Ratio}{subsection.4.8}% 75
\BOOKMARK [4][-]{paragraph.4.8.4.1}{Estimating `39`42`"613A``45`47`"603AE[K] and Var[SRk"0362SRk]}{subsubsection.4.8.4}% 76
\BOOKMARK [1][-]{section.5}{Framework Implementation}{}% 77
\BOOKMARK [2][-]{subsection.5.1}{Full Framework Process}{section.5}% 78
\BOOKMARK [2][-]{subsection.5.2}{Process Diagram}{section.5}% 79
\BOOKMARK [2][-]{subsection.5.3}{Parameter Space Exploration}{section.5}% 80
\BOOKMARK [2][-]{subsection.5.4}{Reproducibility}{section.5}% 81
\BOOKMARK [2][-]{subsection.5.5}{Synthetic Data}{section.5}% 82
\BOOKMARK [2][-]{subsection.5.6}{Data Preparation}{section.5}% 83
\BOOKMARK [3][-]{subsubsection.5.6.1}{Data Window Aggregations}{subsection.5.6}% 84
\BOOKMARK [3][-]{subsubsection.5.6.2}{Point Predictions}{subsection.5.6}% 85
\BOOKMARK [3][-]{subsubsection.5.6.3}{Scaling}{subsection.5.6}% 86
\BOOKMARK [2][-]{subsection.5.7}{Data Partitioning}{section.5}% 87
\BOOKMARK [2][-]{subsection.5.8}{Unsupervised Learning: SAE Training}{section.5}% 88
\BOOKMARK [2][-]{subsection.5.9}{Supervised Learning: Prediction Network Training}{section.5}% 89
\BOOKMARK [2][-]{subsection.5.10}{Price Reconstruction}{section.5}% 90
\BOOKMARK [2][-]{subsection.5.11}{Money Management Strategy}{section.5}% 91
\BOOKMARK [2][-]{subsection.5.12}{Probability of Backtest Overfitting}{section.5}% 92
\BOOKMARK [2][-]{subsection.5.13}{Deflated Sharpe Ratio}{section.5}% 93
\BOOKMARK [1][-]{section.6}{Software Libraries and Development}{}% 94
\BOOKMARK [2][-]{subsection.6.1}{Online Availability}{section.6}% 95
\BOOKMARK [2][-]{subsection.6.2}{Programming Languages}{section.6}% 96
\BOOKMARK [2][-]{subsection.6.3}{Data Generation \046 Processing}{section.6}% 97
\BOOKMARK [2][-]{subsection.6.4}{Network Training}{section.6}% 98
\BOOKMARK [2][-]{subsection.6.5}{Process Implementation}{section.6}% 99
\BOOKMARK [2][-]{subsection.6.6}{Process Reproducibility}{section.6}% 100
\BOOKMARK [2][-]{subsection.6.7}{Database Implementation}{section.6}% 101
\BOOKMARK [2][-]{subsection.6.8}{Diagnostic Libraries}{section.6}% 102
\BOOKMARK [3][-]{subsubsection.6.8.1}{DSR Libraries}{subsection.6.8}% 103
\BOOKMARK [1][-]{section.7}{Datasets Used}{}% 104
\BOOKMARK [2][-]{subsection.7.1}{Actual Datasets}{section.7}% 105
\BOOKMARK [3][-]{subsubsection.7.1.1}{``Actual10''}{subsection.7.1}% 106
\BOOKMARK [3][-]{subsubsection.7.1.2}{``Scaling10''}{subsection.7.1}% 107
\BOOKMARK [3][-]{subsubsection.7.1.3}{``AGL'' and ``AGL\046ACL''}{subsection.7.1}% 108
\BOOKMARK [2][-]{subsection.7.2}{Synthetic Datasets}{section.7}% 109
\BOOKMARK [3][-]{subsubsection.7.2.1}{``Synthetic6''}{subsection.7.2}% 110
\BOOKMARK [3][-]{subsubsection.7.2.2}{``Synthetic10''}{subsection.7.2}% 111
\BOOKMARK [1][-]{section.8}{Results}{}% 112
\BOOKMARK [2][-]{subsection.8.1}{Introduction}{section.8}% 113
\BOOKMARK [3][-]{subsubsection.8.1.1}{Technical Notes}{subsection.8.1}% 114
\BOOKMARK [2][-]{subsection.8.2}{Primary Determinants of OOS P\046L}{section.8}% 115
\BOOKMARK [3][-]{subsubsection.8.2.1}{Effects of Data Horizon Aggregations}{subsection.8.2}% 116
\BOOKMARK [3][-]{subsubsection.8.2.2}{OGD Learning Rate}{subsection.8.2}% 117
\BOOKMARK [3][-]{subsubsection.8.2.3}{Feature Selection}{subsection.8.2}% 118
\BOOKMARK [2][-]{subsection.8.3}{Value of Historical Signal}{section.8}% 119
\BOOKMARK [2][-]{subsection.8.4}{Weight Initializaton Techniques}{section.8}% 120
\BOOKMARK [3][-]{subsubsection.8.4.1}{RBM Pretraining for Sigmoid Networks}{subsection.8.4}% 121
\BOOKMARK [3][-]{subsubsection.8.4.2}{Variance Based Weight Initialization Techniques}{subsection.8.4}% 122
\BOOKMARK [2][-]{subsection.8.5}{Synthetic Data}{section.8}% 123
\BOOKMARK [3][-]{subsubsection.8.5.1}{GBM Generated Data}{subsection.8.5}% 124
\BOOKMARK [3][-]{subsubsection.8.5.2}{Synthetic Data Horizon Effects}{subsection.8.5}% 125
\BOOKMARK [2][-]{subsection.8.6}{Complexity of Financial Time Series}{section.8}% 126
\BOOKMARK [3][-]{subsubsection.8.6.1}{Data Scaling}{subsection.8.6}% 127
\BOOKMARK [3][-]{subsubsection.8.6.2}{SAE Reproduction}{subsection.8.6}% 128
\BOOKMARK [3][-]{subsubsection.8.6.3}{FFN Prediction}{subsection.8.6}% 129
\BOOKMARK [2][-]{subsection.8.7}{Network Structure}{section.8}% 130
\BOOKMARK [3][-]{subsubsection.8.7.1}{Effects of Network Size}{subsection.8.7}% 131
\BOOKMARK [3][-]{subsubsection.8.7.2}{Effects of Activation Functions}{subsection.8.7}% 132
\BOOKMARK [3][-]{subsubsection.8.7.3}{Predictive FFN Activations}{subsection.8.7}% 133
\BOOKMARK [3][-]{subsubsection.8.7.4}{Sigmoid Activation Functions}{subsection.8.7}% 134
\BOOKMARK [3][-]{subsubsection.8.7.5}{Leaky ReLU vs. ReLU}{subsection.8.7}% 135
\BOOKMARK [2][-]{subsection.8.8}{Money Management Strategy}{section.8}% 136
\BOOKMARK [2][-]{subsection.8.9}{Probability of Backtest Overfitting}{section.8}% 137
\BOOKMARK [3][-]{subsubsection.8.9.1}{Concerns Regarding the PBO Calculation}{subsection.8.9}% 138
\BOOKMARK [3][-]{subsubsection.8.9.2}{PBO Results}{subsection.8.9}% 139
\BOOKMARK [3][-]{subsubsection.8.9.3}{Framework Success}{subsection.8.9}% 140
\BOOKMARK [2][-]{subsection.8.10}{Deflated Sharpe Ratio}{section.8}% 141
\BOOKMARK [3][-]{subsubsection.8.10.1}{Computational Complexity}{subsection.8.10}% 142
\BOOKMARK [3][-]{subsubsection.8.10.2}{ONC Results}{subsection.8.10}% 143
\BOOKMARK [3][-]{subsubsection.8.10.3}{DSR and PSR Results}{subsection.8.10}% 144
\BOOKMARK [3][-]{subsubsection.8.10.4}{Framework Success}{subsection.8.10}% 145
\BOOKMARK [2][-]{subsection.8.11}{Summary of Actual and Synthetic Data Effects}{section.8}% 146
\BOOKMARK [2][-]{subsection.8.12}{Personal Thoughts on Mechanistic Machine Learning Approaches}{section.8}% 147
\BOOKMARK [3][-]{subsubsection.8.12.1}{On Backtest Overfitting and Validation}{subsection.8.12}% 148
\BOOKMARK [3][-]{subsubsection.8.12.2}{On the Profitability of Machine Learning Models}{subsection.8.12}% 149
\BOOKMARK [3][-]{subsubsection.8.12.3}{On the Development of Machine Learning Frameworks}{subsection.8.12}% 150
\BOOKMARK [1][-]{section.9}{Conclusion}{}% 151
\BOOKMARK [1][-]{section.10}{Future Work}{}% 152
\BOOKMARK [1][-]{section.11}{Appendix}{}% 153
\BOOKMARK [2][-]{subsection.11.1}{Additional Results}{section.11}% 154
\BOOKMARK [3][-]{subsubsection.11.1.1}{Additional Results for Section 8.2 - Feature Selection }{subsection.11.1}% 155
\BOOKMARK [3][-]{subsubsection.11.1.2}{Additional Results for Section 8.4 - Weight Initialization Techniques }{subsection.11.1}% 156
\BOOKMARK [3][-]{subsubsection.11.1.3}{Additional Results for Section 8.6 - Complexity of Financial Time Series}{subsection.11.1}% 157
\BOOKMARK [3][-]{subsubsection.11.1.4}{Additional Results for Section 8.7 - Network Structure and Training }{subsection.11.1}% 158
\BOOKMARK [2][-]{subsection.11.2}{`How To' Guide for Julia Libraries}{section.11}% 159
\BOOKMARK [3][-]{subsubsection.11.2.1}{Create the Database}{subsection.11.2}% 160
\BOOKMARK [3][-]{subsubsection.11.2.2}{Data Specifications}{subsection.11.2}% 161
\BOOKMARK [3][-]{subsubsection.11.2.3}{Train SAE Networks}{subsection.11.2}% 162
\BOOKMARK [3][-]{subsubsection.11.2.4}{Select Best SAE Networks}{subsection.11.2}% 163
\BOOKMARK [3][-]{subsubsection.11.2.5}{Train FFN Networks}{subsection.11.2}% 164
\BOOKMARK [3][-]{subsubsection.11.2.6}{Run Batch Process Diagnostics}{subsection.11.2}% 165
\BOOKMARK [3][-]{subsubsection.11.2.7}{Diagnostic Visualizations}{subsection.11.2}% 166
\BOOKMARK [3][-]{subsubsection.11.2.8}{CSCV \046 PBO}{subsection.11.2}% 167
\BOOKMARK [3][-]{subsubsection.11.2.9}{DSR}{subsection.11.2}% 168
\BOOKMARK [2][-]{subsection.11.3}{Relational Database Schema Diagram}{section.11}% 169
\BOOKMARK [2][-]{subsection.11.4}{Dataset Information}{section.11}% 170
\BOOKMARK [2][-]{subsection.11.5}{Configuration Sets Used}{section.11}% 171
\BOOKMARK [3][-]{subsubsection.11.5.1}{Configuration 1}{subsection.11.5}% 172
\BOOKMARK [3][-]{subsubsection.11.5.2}{Configuration 2}{subsection.11.5}% 173
\BOOKMARK [3][-]{subsubsection.11.5.3}{Configuration 3}{subsection.11.5}% 174
\BOOKMARK [3][-]{subsubsection.11.5.4}{Configuration 4}{subsection.11.5}% 175
\BOOKMARK [3][-]{subsubsection.11.5.5}{Configuration 5}{subsection.11.5}% 176
\BOOKMARK [3][-]{subsubsection.11.5.6}{Configuration 6}{subsection.11.5}% 177
\BOOKMARK [3][-]{subsubsection.11.5.7}{Configuration 7}{subsection.11.5}% 178
\BOOKMARK [3][-]{subsubsection.11.5.8}{Configuration 8}{subsection.11.5}% 179
\BOOKMARK [3][-]{subsubsection.11.5.9}{Configuration 9}{subsection.11.5}% 180
\BOOKMARK [3][-]{subsubsection.11.5.10}{Configuration 10}{subsection.11.5}% 181
\BOOKMARK [3][-]{subsubsection.11.5.11}{Configuration 11}{subsection.11.5}% 182
\BOOKMARK [3][-]{subsubsection.11.5.12}{Configuration 12}{subsection.11.5}% 183
\BOOKMARK [3][-]{subsubsection.11.5.13}{Configuration 13}{subsection.11.5}% 184
\BOOKMARK [3][-]{subsubsection.11.5.14}{Configuration 14}{subsection.11.5}% 185
\BOOKMARK [3][-]{subsubsection.11.5.15}{Configuration 15}{subsection.11.5}% 186
\BOOKMARK [3][-]{subsubsection.11.5.16}{Configuration 16}{subsection.11.5}% 187
\BOOKMARK [3][-]{subsubsection.11.5.17}{Configuration 17}{subsection.11.5}% 188
\BOOKMARK [2][-]{subsection.11.6}{Diagnostic Charts}{section.11}% 189
\BOOKMARK [1][-]{section.12}{References}{}% 190
