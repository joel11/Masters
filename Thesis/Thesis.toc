\select@language {english}
\contentsline {paragraph}{Weight Initializations}{2}{section*.1}
\contentsline {paragraph}{Network Structures}{3}{section*.4}
\contentsline {paragraph}{Data Windows}{3}{section*.7}
\contentsline {paragraph}{Best network performance}{4}{section*.10}
\contentsline {paragraph}{Regularization}{5}{section*.13}
\contentsline {paragraph}{Linear vs ReLU: Smaller Network}{6}{section*.15}
\contentsline {paragraph}{Leaky ReLU vs ReLU}{6}{section*.17}
\contentsline {paragraph}{SAE Selection: MSE vs MAPE}{7}{section*.20}
\contentsline {paragraph}{L1 Regularization}{7}{section*.22}
\contentsline {paragraph}{Learning Rate Schedule Implementation}{8}{section*.24}
\contentsline {paragraph}{Denoising - On/Off Feature Selection}{8}{section*.26}
\contentsline {paragraph}{Validation Set Percentage}{9}{section*.28}
\contentsline {subsection}{\numberline {0.1}Limited Synthetic Asset Tests}{9}{subsection.0.1}
\contentsline {paragraph}{1 Asset}{9}{section*.30}
\contentsline {paragraph}{2 Asset}{10}{section*.34}
\contentsline {paragraph}{3 Asset}{12}{section*.39}
\contentsline {paragraph}{4 Asset}{13}{section*.43}
\contentsline {paragraph}{Effect of Rolling Window Sizes}{14}{section*.47}
\contentsline {paragraph}{Sigmoid Pre-training Efficacy}{15}{section*.49}
\contentsline {paragraph}{SAE Linear Activation Tests}{16}{section*.53}
\contentsline {paragraph}{Denoising SAEs}{18}{section*.59}
\contentsline {paragraph}{Linear Activations in FFN}{18}{section*.61}
\contentsline {paragraph}{SAE Effects}{19}{section*.63}
\contentsline {paragraph}{Predictive Network Sizes}{19}{section*.65}
\contentsline {paragraph}{Cross Validation Effects}{20}{section*.67}
\contentsline {paragraph}{Returns Analysis}{20}{section*.69}
\contentsline {paragraph}{Scaling}{23}{section*.75}
\contentsline {paragraph}{General Configurations \& CV}{24}{section*.79}
\contentsline {paragraph}{Return Graphs}{26}{section*.84}
\contentsline {paragraph}{Price Predictions}{28}{section*.88}
\contentsline {paragraph}{Sigmoid Pre-training}{31}{section*.95}
\contentsline {paragraph}{Next Iteration}{32}{section*.97}
\contentsline {paragraph}{Iteration Output}{32}{section*.98}
\contentsline {paragraph}{Critical Decisions and Points of Concern}{32}{section*.99}
\contentsline {paragraph}{Dissertation to-do list}{32}{section*.100}
\contentsline {paragraph}{General Configuration}{33}{section*.101}
\contentsline {paragraph}{SAE Configurations (945)}{33}{section*.102}
\contentsline {paragraph}{FFN Configurations (2835)}{33}{section*.103}
\contentsline {paragraph}{16th June 2018}{36}{section*.105}
\contentsline {paragraph}{29th March 2019}{36}{section*.106}
\contentsline {paragraph}{12th April 2019}{37}{section*.107}
\contentsline {paragraph}{26th April 2019}{38}{section*.108}
\contentsline {paragraph}{17th May 2019}{39}{section*.109}
\contentsline {section}{\numberline {1}Introduction}{4}{section.1}
\contentsline {section}{\numberline {2}LiteratureReview}{5}{section.2}
\contentsline {subsection}{\numberline {2.1}Technical Analysis}{5}{subsection.2.1}
\contentsline {subsection}{\numberline {2.2}Neural Networks}{5}{subsection.2.2}
\contentsline {subsubsection}{\numberline {2.2.1}Training and Backpropagation}{6}{subsubsection.2.2.1}
\contentsline {subsubsection}{\numberline {2.2.2}Activation Functions}{6}{subsubsection.2.2.2}
\contentsline {subsubsection}{\numberline {2.2.3}Deep Learning}{6}{subsubsection.2.2.3}
\contentsline {subsubsection}{\numberline {2.2.4}Backpropagation Improvements}{7}{subsubsection.2.2.4}
\contentsline {subsection}{\numberline {2.3}Stacked Autoencoders}{7}{subsection.2.3}
\contentsline {subsubsection}{\numberline {2.3.1}High Dimensional Data Reduction}{7}{subsubsection.2.3.1}
\contentsline {subsubsection}{\numberline {2.3.2}Deep Belief Networks}{8}{subsubsection.2.3.2}
\contentsline {subsubsection}{\numberline {2.3.3}Stacked Denoising Autoencoders}{9}{subsubsection.2.3.3}
\contentsline {subsubsection}{\numberline {2.3.4}Pre-training}{9}{subsubsection.2.3.4}
\contentsline {subsubsection}{\numberline {2.3.5}Time Series Applications}{9}{subsubsection.2.3.5}
\contentsline {subsubsection}{\numberline {2.3.6}Financial Applications}{9}{subsubsection.2.3.6}
\contentsline {subsection}{\numberline {2.4}Data Segmentation}{10}{subsection.2.4}
\contentsline {subsection}{\numberline {2.5}Online Learning Algorithms and Gradient Descent}{11}{subsection.2.5}
\contentsline {subsection}{\numberline {2.6}Backtesting and Model Validation}{12}{subsection.2.6}
\contentsline {subsubsection}{\numberline {2.6.1}Testing Methodologies}{12}{subsubsection.2.6.1}
\contentsline {subsubsection}{\numberline {2.6.2}Test Data Length}{13}{subsubsection.2.6.2}
\contentsline {subsubsection}{\numberline {2.6.3}Sharpe Ratio}{14}{subsubsection.2.6.3}
\contentsline {section}{\numberline {3}Data}{15}{section.3}
\contentsline {subsection}{\numberline {3.1}Data Processing}{15}{subsection.3.1}
\contentsline {subsubsection}{\numberline {3.1.1}Log Difference Transformation and Aggregation}{15}{subsubsection.3.1.1}
\contentsline {subsubsection}{\numberline {3.1.2}Data Scaling}{15}{subsubsection.3.1.2}
\contentsline {subsubsection}{\numberline {3.1.3}Reverse Data Scaling}{15}{subsubsection.3.1.3}
\contentsline {subsubsection}{\numberline {3.1.4}Price Reconstruction}{15}{subsubsection.3.1.4}
\contentsline {subsection}{\numberline {3.2}Synthetic Data}{16}{subsection.3.2}
\contentsline {paragraph}{Simulated Dataset}{16}{section*.118}
\contentsline {subsection}{\numberline {3.3}Real Data}{16}{subsection.3.3}
\contentsline {section}{\numberline {4}Implementation}{17}{section.4}
\contentsline {subsection}{\numberline {4.1}Process Overview}{17}{subsection.4.1}
\contentsline {subsection}{\numberline {4.2}Feedforward Neural Networks}{17}{subsection.4.2}
\contentsline {subsubsection}{\numberline {4.2.1}Notation and Network Representation}{17}{subsubsection.4.2.1}
\contentsline {subsubsection}{\numberline {4.2.2}Activation Functions}{17}{subsubsection.4.2.2}
\contentsline {subparagraph}{Sigmoid}{17}{section*.121}
\contentsline {subparagraph}{ReLU}{18}{section*.122}
\contentsline {subsubsection}{\numberline {4.2.3}Backpropagation}{18}{subsubsection.4.2.3}
\contentsline {subsubsection}{\numberline {4.2.4}Gradient Descent Algorithms}{18}{subsubsection.4.2.4}
\contentsline {subsubsection}{\numberline {4.2.5}Gradient Descent Improvements}{19}{subsubsection.4.2.5}
\contentsline {subsection}{\numberline {4.3}Restricted Boltzmann Machines}{19}{subsection.4.3}
\contentsline {subsubsection}{\numberline {4.3.1}Contrastive Divergence}{19}{subsubsection.4.3.1}
\contentsline {subsubsection}{\numberline {4.3.2}CD-1 and SGD}{20}{subsubsection.4.3.2}
\contentsline {subsection}{\numberline {4.4}Stacked Autoencoders}{20}{subsection.4.4}
\contentsline {subsubsection}{\numberline {4.4.1}Sigmoid based Greedy Layerwise SAE Training}{20}{subsubsection.4.4.1}
\contentsline {subsubsection}{\numberline {4.4.2}ReLU based SAE Training}{20}{subsubsection.4.4.2}
\contentsline {subsubsection}{\numberline {4.4.3}Denoising Autoencoders}{21}{subsubsection.4.4.3}
\contentsline {subsection}{\numberline {4.5}Variance Based Weight Initializations}{21}{subsection.4.5}
\contentsline {subsection}{\numberline {4.6}Learning Optimizations}{21}{subsection.4.6}
\contentsline {subsubsection}{\numberline {4.6.1}Regularization}{21}{subsubsection.4.6.1}
\contentsline {subsubsection}{\numberline {4.6.2}Learning Rate Schedule}{21}{subsubsection.4.6.2}
\contentsline {subsection}{\numberline {4.7}CSCV \& PBO}{21}{subsection.4.7}
\contentsline {subsection}{\numberline {4.8}Performance Assessment}{22}{subsection.4.8}
\contentsline {subsection}{\numberline {4.9}Money Management Strategy and Returns}{23}{subsection.4.9}
\contentsline {subsection}{\numberline {4.10}Full Process Implementation}{24}{subsection.4.10}
\contentsline {section}{\numberline {5}Results}{25}{section.5}
\contentsline {subsection}{\numberline {5.1}Datasets Used}{25}{subsection.5.1}
\contentsline {subsubsection}{\numberline {5.1.1}Synthetic6}{25}{subsubsection.5.1.1}
\contentsline {subsubsection}{\numberline {5.1.2}Synthetic10}{25}{subsubsection.5.1.2}
\contentsline {subsubsection}{\numberline {5.1.3}AGL}{25}{subsubsection.5.1.3}
\contentsline {subsubsection}{\numberline {5.1.4}AGL\&ACL}{25}{subsubsection.5.1.4}
\contentsline {subsubsection}{\numberline {5.1.5}Actual10}{25}{subsubsection.5.1.5}
\contentsline {subsection}{\numberline {5.2}Linearity, Complexity and Structure of Data}{25}{subsection.5.2}
\contentsline {subsubsection}{\numberline {5.2.1}GBM Generated Data}{25}{subsubsection.5.2.1}
\contentsline {subsubsection}{\numberline {5.2.2}Activations: Linear, Sigmoid, ReLU and Leaky ReLU}{25}{subsubsection.5.2.2}
\contentsline {paragraph}{SAE Activations and Scaling}{26}{section*.136}
\contentsline {paragraph}{Predictive FFN Activations and Scaling}{26}{section*.139}
\contentsline {paragraph}{Leaky ReLU vs ReLU}{27}{section*.141}
\contentsline {subsubsection}{\numberline {5.2.3}Effects of Network Size}{27}{subsubsection.5.2.3}
\contentsline {subsection}{\numberline {5.3}Feature Selection and Data Aggregation}{28}{subsection.5.3}
\contentsline {paragraph}{Feature Selection}{28}{section*.146}
\contentsline {paragraph}{Data Aggregation}{28}{section*.148}
\contentsline {paragraph}{Historical Data and SGD training}{29}{section*.151}
\contentsline {subsection}{\numberline {5.4}Weight Initialization Techniques}{30}{subsection.5.4}
\contentsline {subsubsection}{\numberline {5.4.1}RBM Pretraining for Sigmoid Networks}{30}{subsubsection.5.4.1}
\contentsline {paragraph}{Sigmoid Activation Functions}{30}{section*.154}
\contentsline {subsubsection}{\numberline {5.4.2}Variance Based Weight Initialization Techniques}{31}{subsubsection.5.4.2}
\contentsline {subsection}{\numberline {5.5}Learning Optimizations}{32}{subsection.5.5}
\contentsline {subsubsection}{\numberline {5.5.1}Learning Rate Schedules}{32}{subsubsection.5.5.1}
\contentsline {subsubsection}{\numberline {5.5.2}Regularization}{33}{subsubsection.5.5.2}
\contentsline {subsubsection}{\numberline {5.5.3}Denoising}{34}{subsubsection.5.5.3}
\contentsline {section}{\numberline {6}Conclusions}{35}{section.6}
\contentsline {section}{\numberline {7}Appendix}{35}{section.7}
\contentsline {subsection}{\numberline {7.1}Additional Results}{35}{subsection.7.1}
\contentsline {subsubsection}{\numberline {7.1.1}Effects of Network Size on SAE and FFN for Synthetic Data}{35}{subsubsection.7.1.1}
\contentsline {subsection}{\numberline {7.2}Configuration Sets Used}{35}{subsection.7.2}
\contentsline {subsubsection}{\numberline {7.2.1}Configuration1 - SAE}{35}{subsubsection.7.2.1}
\contentsline {subsubsection}{\numberline {7.2.2}Config2 - Predictive FFN}{36}{subsubsection.7.2.2}
\contentsline {subsubsection}{\numberline {7.2.3}Configuration3 - SAE}{36}{subsubsection.7.2.3}
\contentsline {subsubsection}{\numberline {7.2.4}Configuration4 - Predictive FFN}{36}{subsubsection.7.2.4}
\contentsline {subsubsection}{\numberline {7.2.5}Configuration5 - SAE}{37}{subsubsection.7.2.5}
\contentsline {subsubsection}{\numberline {7.2.6}Configuration6 - Predictive FFN}{37}{subsubsection.7.2.6}
\contentsline {subsubsection}{\numberline {7.2.7}Configuration7 - SAE}{37}{subsubsection.7.2.7}
\contentsline {section}{\numberline {8}References}{38}{section.8}
