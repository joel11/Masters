\relax 
\providecommand\hyper@newdestlabel[2]{}
\catcode `"\active 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\tcolorbox@label[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {paragraph}{Sigmoid Pre-training Efficacy}{3}{section*.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SAE MSE By Scaling \newline  The three series above show the classification accuracy scores (percentage) by epoch on an AutoEncoder which was used to classify MNIST images. The series were trained with 0, 1 and 5 pre-training epochs, and show a clear improvment in having an epoch of pre-training in the SAE formation (though not much for more than 1).\relax }}{3}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figure-pretraining-effect}{{1}{3}{SAE MSE By Scaling \newline The three series above show the classification accuracy scores (percentage) by epoch on an AutoEncoder which was used to classify MNIST images. The series were trained with 0, 1 and 5 pre-training epochs, and show a clear improvment in having an epoch of pre-training in the SAE formation (though not much for more than 1).\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Pre-training Effects on financial SAE \newline  The boxplots here show the summary of configuration performances, by minimum MSE achieved, grouped according to the number of pre-training epochs which the network had. There is a clear favour to having no pre-training in this scenario.\relax }}{3}{figure.caption.3}}
\newlabel{figure-it2-pretraining-effect}{{2}{3}{Pre-training Effects on financial SAE \newline The boxplots here show the summary of configuration performances, by minimum MSE achieved, grouped according to the number of pre-training epochs which the network had. There is a clear favour to having no pre-training in this scenario.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Pre-training Effects on financial SAE, by learning rate \newline  These boxplots show the same as above, but further grouped by learning rate. We can see the few samples that appears to be benefiting from having 1 epoch of pre-training are simply a result of the learning rate being small enough so as not to have much effect.\relax }}{4}{figure.caption.4}}
\newlabel{figure-it2-pretraining-effect2}{{3}{4}{Pre-training Effects on financial SAE, by learning rate \newline These boxplots show the same as above, but further grouped by learning rate. We can see the few samples that appears to be benefiting from having 1 epoch of pre-training are simply a result of the learning rate being small enough so as not to have much effect.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {paragraph}{SAE Linear Activation Tests}{4}{section*.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Effects of Standardizing \& ReLU Output \newline  These boxplots show the MSE scores for the combinations run grouped by 'Hidden Activation-Encoding Activation-Output Activation-Scaling Technique. There is significantly poorer performance when Standardizing is used instead of Normalizing or when there is a ReLU output activation. These configurations are excluded from the graphs below.\relax }}{4}{figure.caption.6}}
\newlabel{figure-it2-scaling-and-relu}{{4}{4}{Effects of Standardizing \& ReLU Output \newline These boxplots show the MSE scores for the combinations run grouped by 'Hidden Activation-Encoding Activation-Output Activation-Scaling Technique. There is significantly poorer performance when Standardizing is used instead of Normalizing or when there is a ReLU output activation. These configurations are excluded from the graphs below.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Effects of Linear Activation \newline  This is the same data as in Figure 4, focusing on the more effective configurations. We can see Sigmoid has largely poor performance unless there is a Linear encoding layer (a widely experienced behaviour), and seems mostly unable to outperform a fully linear network. The best configuration is Relu Hidden layers, with Linear encoding and Output - this makes sense with the non-linear benefit at hidden layers but with less loss of error signal and information at the output and encoding layers.\relax }}{5}{figure.caption.7}}
\newlabel{figure-it2-linear-act}{{5}{5}{Effects of Linear Activation \newline This is the same data as in Figure 4, focusing on the more effective configurations. We can see Sigmoid has largely poor performance unless there is a Linear encoding layer (a widely experienced behaviour), and seems mostly unable to outperform a fully linear network. The best configuration is Relu Hidden layers, with Linear encoding and Output - this makes sense with the non-linear benefit at hidden layers but with less loss of error signal and information at the output and encoding layers.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Encoding Size 25 \newline  These plots show the performance for all configurations with an encoding layer size of 25 (input 30). There is once again a surprisingly high performance in the fully linear network.\relax }}{5}{figure.caption.8}}
\newlabel{figure-it2-encoding25}{{6}{5}{Encoding Size 25 \newline These plots show the performance for all configurations with an encoding layer size of 25 (input 30). There is once again a surprisingly high performance in the fully linear network.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Encoding Size 5 \newline  These plots show the performance for all configurations with an encoding layer size of 5 (input 30). Here we finally see the benefit of non-linear activations in the ReLU based newtorks, which the fully linear is not able to outperform.\relax }}{5}{figure.caption.9}}
\newlabel{figure-it2-encoding5}{{7}{5}{Encoding Size 5 \newline These plots show the performance for all configurations with an encoding layer size of 5 (input 30). Here we finally see the benefit of non-linear activations in the ReLU based newtorks, which the fully linear is not able to outperform.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Performance by Network Size \newline  We can further break these down by network size, and see performance is as one would hope, with the best ReLU configurations corresponding with more layers and of larger sizes.\relax }}{6}{figure.caption.10}}
\newlabel{figure-it2-networksize-effect}{{8}{6}{Performance by Network Size \newline We can further break these down by network size, and see performance is as one would hope, with the best ReLU configurations corresponding with more layers and of larger sizes.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Denoising SAEs}{6}{section*.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Performance by Denoising Variation \newline  The above groupings show the decreasing SAE performance as the level of denoising is increased. The grouping with variance 1.0e-11 essentially represents no denoising.\relax }}{6}{figure.caption.12}}
\newlabel{figure-it2-denoise}{{9}{6}{Performance by Denoising Variation \newline The above groupings show the decreasing SAE performance as the level of denoising is increased. The grouping with variance 1.0e-11 essentially represents no denoising.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Linear Activations in FFN}{6}{section*.13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Linear Activations in FFN \newline  The above groupings show the profits generated for different combinations of Hidden Activation - Output Activation - Scaling Method (which is for both SAE and FFN). There are several takeaways: \newline  1. Higher performance of Linear networks (may be down to network size and amount of input data) \newline  2. The limited scaling technique is having a noticeable impact on profits \newline  3. The decrease in performance with ReLU output persists \relax }}{7}{figure.caption.14}}
\newlabel{figure-it2-linear-ffn_activations}{{10}{7}{Linear Activations in FFN \newline The above groupings show the profits generated for different combinations of Hidden Activation - Output Activation - Scaling Method (which is for both SAE and FFN). There are several takeaways: \newline 1. Higher performance of Linear networks (may be down to network size and amount of input data) \newline 2. The limited scaling technique is having a noticeable impact on profits \newline 3. The decrease in performance with ReLU output persists \relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {paragraph}{Scaling}{8}{section*.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces SAE MSE By Scaling\relax }}{8}{figure.caption.16}}
\newlabel{figure-synthetic-prices}{{11}{8}{SAE MSE By Scaling\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces OGD MSE By Scaling\relax }}{8}{figure.caption.17}}
\newlabel{figure-synthetic-prices}{{12}{8}{OGD MSE By Scaling\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces OGD Profits by Scaling\relax }}{9}{figure.caption.18}}
\newlabel{figure-synthetic-prices}{{13}{9}{OGD Profits by Scaling\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {paragraph}{General Configurations \& CV}{9}{section*.19}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Price Plot\relax }}{10}{figure.caption.20}}
\newlabel{figure-synthetic-prices}{{14}{10}{Price Plot\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces PDF of all Profits Generated\relax }}{10}{figure.caption.21}}
\newlabel{figure-synthetic-prices}{{15}{10}{PDF of all Profits Generated\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces SAE Profits\relax }}{11}{figure.caption.22}}
\newlabel{figure-synthetic-prices}{{16}{11}{SAE Profits\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Network Structure Profits\relax }}{11}{figure.caption.23}}
\newlabel{figure-synthetic-prices}{{17}{11}{Network Structure Profits\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {paragraph}{Return Graphs}{11}{section*.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Cumulative Profits\relax }}{12}{figure.caption.25}}
\newlabel{figure-synthetic-prices}{{18}{12}{Cumulative Profits\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Cumulative Return Rates\relax }}{12}{figure.caption.26}}
\newlabel{figure-synthetic-prices}{{19}{12}{Cumulative Return Rates\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Daily Rates\relax }}{13}{figure.caption.27}}
\newlabel{figure-synthetic-prices}{{20}{13}{Daily Rates\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {paragraph}{Price Predictions}{13}{section*.28}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Stock 1\relax }}{13}{figure.caption.29}}
\newlabel{figure-synthetic-prices}{{21}{13}{Stock 1\relax }{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Stock 2\relax }}{14}{figure.caption.30}}
\newlabel{figure-synthetic-prices}{{22}{14}{Stock 2\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Stock 3\relax }}{14}{figure.caption.31}}
\newlabel{figure-synthetic-prices}{{23}{14}{Stock 3\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Stock 4\relax }}{15}{figure.caption.32}}
\newlabel{figure-synthetic-prices}{{24}{15}{Stock 4\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Stock 5\relax }}{15}{figure.caption.33}}
\newlabel{figure-synthetic-prices}{{25}{15}{Stock 5\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Stock 6\relax }}{16}{figure.caption.34}}
\newlabel{figure-synthetic-prices}{{26}{16}{Stock 6\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {paragraph}{Sigmoid Pre-training}{16}{section*.35}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Stock 6\relax }}{16}{figure.caption.36}}
\newlabel{Pre-training MSE performance}{{27}{16}{Stock 6\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {paragraph}{Next Iteration}{17}{section*.37}}
\@writefile{toc}{\contentsline {paragraph}{Critical Decisions and Points of Concern}{17}{section*.38}}
\@writefile{toc}{\contentsline {paragraph}{Non-Critical Features}{17}{section*.39}}
\@writefile{toc}{\contentsline {paragraph}{Dissertation to-do list}{17}{section*.40}}
\@writefile{toc}{\contentsline {paragraph}{16th June 2018}{20}{section*.42}}
\@writefile{toc}{\contentsline {paragraph}{29th March 2019}{20}{section*.43}}
\@writefile{toc}{\contentsline {paragraph}{12th April 2019}{21}{section*.44}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ this will need to be rewritten once everything is finalised}{1}{section*.45}}
\pgfsyspdfmark {pgfid2}{29757314}{41226139}
\pgfsyspdfmark {pgfid5}{39492954}{41238427}
\pgfsyspdfmark {pgfid6}{41344346}{41014513}
\citation{BailyPBO}
\citation{Hinton2}
\citation{BailyPBO}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\newlabel{Introduction}{{1}{3}{Introduction}{section.1}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ may need to add some appropriate in this section}{3}{section*.47}}
\pgfsyspdfmark {pgfid7}{2237610}{50145408}
\pgfsyspdfmark {pgfid10}{39492954}{50157696}
\pgfsyspdfmark {pgfid11}{41344346}{49933782}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{red}{}{red!25}{\leavevmode {\color  {red!25}o}}\ check this}{3}{section*.48}}
\pgfsyspdfmark {pgfid12}{31717939}{22882432}
\pgfsyspdfmark {pgfid15}{39492954}{22894720}
\pgfsyspdfmark {pgfid16}{41344346}{22670806}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ add ref}{3}{section*.49}}
\pgfsyspdfmark {pgfid17}{18424594}{18163840}
\pgfsyspdfmark {pgfid20}{39492954}{18176128}
\pgfsyspdfmark {pgfid21}{41344346}{17952214}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ this will need to be finished once results are known}{3}{section*.50}}
\pgfsyspdfmark {pgfid22}{25399160}{14231680}
\pgfsyspdfmark {pgfid25}{39492954}{14243968}
\pgfsyspdfmark {pgfid26}{41344346}{14020054}
\citation{Murphy}
\citation{Murphy}
\citation{Griffioen}
\citation{Kahn}
\citation{Schwager}
\citation{Johnson}
\citation{Arthur}
\citation{Crutchfield}
\citation{Skabar}
\citation{Schmidhuber}
\citation{Ivakhnenko}
\citation{Werbos}
\citation{Siegelmann}
\citation{Hochreiter}
\@writefile{toc}{\contentsline {section}{\numberline {2}LiteratureReview}{4}{section.2}}
\newlabel{lr_LiteratureReview}{{2}{4}{LiteratureReview}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Technical Analysis}{4}{subsection.2.1}}
\newlabel{lr_TechnicalAnalysis}{{2.1}{4}{Technical Analysis}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Networks}{4}{subsection.2.2}}
\newlabel{lr_nn}{{2.2}{4}{Neural Networks}{subsection.2.2}{}}
\citation{Schmidhuber}
\citation{Minksy}
\citation{LeCun2}
\citation{Werbos2}
\citation{Rumelhart}
\citation{LeCun3}
\citation{Pascanu}
\citation{Schmidhuber}
\citation{LeCun4}
\citation{Dauphin}
\citation{Ge}
\citation{Hornik}
\citation{Wu}
\citation{Glorot}
\citation{Glorot2}
\citation{Bengio1}
\citation{Hinton1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Training and Backpropagation}{5}{subsubsection.2.2.1}}
\newlabel{lr_trainingbackprop}{{2.2.1}{5}{Training and Backpropagation}{subsubsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Activation Functions}{5}{subsubsection.2.2.2}}
\newlabel{lr_activationfunctions}{{2.2.2}{5}{Activation Functions}{subsubsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Deep Learning}{5}{subsubsection.2.2.3}}
\citation{Hinton1}
\citation{Ranzato1}
\citation{Hinton2}
\citation{Hinton1}
\citation{LeRoux}
\citation{Bengio2}
\citation{Sermanet}
\citation{ImageNet}
\citation{WaveNet}
\citation{ImageNet}
\citation{Glorot2}
\citation{Ciresan}
\citation{Bengio3}
\citation{Hinton4}
\citation{Goodfellow}
\citation{Wang2}
\citation{Hornik}
\citation{Schaefer}
\citation{Donoho}
\citation{Fan1}
\citation{Fan2}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Backpropagation Improvements}{6}{subsubsection.2.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Stacked Autoencoders}{6}{subsection.2.3}}
\newlabel{lr_SAE}{{2.3}{6}{Stacked Autoencoders}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}High Dimensional Data Reduction}{6}{subsubsection.2.3.1}}
\newlabel{HDDR}{{2.3.1}{6}{High Dimensional Data Reduction}{subsubsection.2.3.1}{}}
\citation{Fama}
\citation{Langkvist}
\citation{Langkvist}
\citation{Hinton1}
\citation{Ranzato1}
\citation{Bengio1}
\citation{Hinton2}
\citation{Hinton3}
\citation{Hinton2}
\citation{Hinton2}
\citation{Vincent}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces The Autoencoder training steps \cite  {Hinton2}\relax }}{7}{figure.caption.51}}
\newlabel{figure-DBN-RBM}{{28}{7}{The Autoencoder training steps \cite {Hinton2}\relax }{figure.caption.51}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Deep Belief Networks}{7}{subsubsection.2.3.2}}
\newlabel{DBN}{{2.3.2}{7}{Deep Belief Networks}{subsubsection.2.3.2}{}}
\citation{Vincent}
\citation{Vincent}
\citation{Erhan}
\citation{Lv}
\citation{Langkvist}
\citation{Takeuchi}
\citation{Zhao}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Stacked Denoising Autoencoders}{8}{subsubsection.2.3.3}}
\newlabel{SDAE}{{2.3.3}{8}{Stacked Denoising Autoencoders}{subsubsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Pre-training}{8}{subsubsection.2.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}Time Series Applications}{8}{subsubsection.2.3.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6}Financial Applications}{8}{subsubsection.2.3.6}}
\citation{Troiano}
\citation{Bao}
\citation{Hsu}
\citation{Chu}
\citation{Bakiri}
\citation{Liu}
\citation{Chung}
\citation{Zhou}
\citation{Yin}
\citation{Wan}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Data Segmentation}{9}{subsection.2.4}}
\citation{Albers}
\citation{Bottou}
\citation{LeCun}
\citation{Bottou2}
\citation{Bottou}
\citation{Shalev}
\citation{Zhang}
\citation{Tseng}
\citation{Bartlett}
\citation{Langford}
\citation{Duchi}
\citation{Zeiler}
\citation{Zinkevich}
\citation{Mahajan}
\citation{Mahajan}
\citation{Povey}
\citation{Wang}
\citation{Devarakonda}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Online Learning Algorithms and Gradient Descent}{10}{subsection.2.5}}
\newlabel{lr_OGD}{{2.5}{10}{Online Learning Algorithms and Gradient Descent}{subsection.2.5}{}}
\citation{Ioannidis}
\citation{BailyPBO}
\citation{McLean}
\citation{Schorfheide}
\citation{Prado}
\citation{Schorfheide}
\citation{Weiss}
\citation{Hawkins}
\citation{BailyPBO}
\citation{Hansen}
\citation{Aparicio}
\citation{BailyPBO}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Backtesting and Model Validation}{11}{subsection.2.6}}
\newlabel{lr_backtesting}{{2.6}{11}{Backtesting and Model Validation}{subsection.2.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Testing Methodologies}{11}{subsubsection.2.6.1}}
\newlabel{lr_cscv}{{2.6.1}{11}{Testing Methodologies}{subsubsection.2.6.1}{}}
\citation{Lo}
\citation{BaileyBTL}
\citation{BaileyBTL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Test Data Length}{12}{subsubsection.2.6.2}}
\newlabel{SRAnnual}{{1}{12}{Test Data Length}{equation.2.1}{}}
\newlabel{SRConvergence}{{2}{12}{Test Data Length}{equation.2.2}{}}
\newlabel{MinBTL}{{3}{12}{Test Data Length}{equation.2.3}{}}
\citation{BaileySharpe}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.3}Sharpe Ratio}{13}{subsubsection.2.6.3}}
\newlabel{SR}{{4}{13}{Sharpe Ratio}{equation.2.4}{}}
\newlabel{tratio}{{5}{13}{Sharpe Ratio}{equation.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data}{14}{section.3}}
\newlabel{Data}{{3}{14}{Data}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Processing}{14}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Log Difference Transformation and Aggregation}{14}{subsubsection.3.1.1}}
\newlabel{ldata_og_difference}{{3.1.1}{14}{Log Difference Transformation and Aggregation}{subsubsection.3.1.1}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Change to final windows decided on}{14}{section*.52}}
\pgfsyspdfmark {pgfid27}{22482800}{36772267}
\pgfsyspdfmark {pgfid30}{39492954}{36784555}
\pgfsyspdfmark {pgfid31}{41344346}{36560641}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Data Scaling}{14}{subsubsection.3.1.2}}
\newlabel{data_scaling}{{3.1.2}{14}{Data Scaling}{subsubsection.3.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Reverse Data Scaling}{14}{subsubsection.3.1.3}}
\newlabel{data_reverse_scaling}{{3.1.3}{14}{Reverse Data Scaling}{subsubsection.3.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}Price Reconstruction}{14}{subsubsection.3.1.4}}
\newlabel{data_price_recon}{{3.1.4}{14}{Price Reconstruction}{subsubsection.3.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Synthetic Data}{15}{subsection.3.2}}
\newlabel{data_synthetic}{{3.2}{15}{Synthetic Data}{subsection.3.2}{}}
\newlabel{algo_brownianmotion}{{1}{15}{Synthetic Data}{algocfline.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Geometric Brownian Motion Simulation\relax }}{15}{algocf.1}}
\@writefile{toc}{\contentsline {paragraph}{Simulated Dataset}{15}{section*.53}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ finish this}{15}{section*.54}}
\pgfsyspdfmark {pgfid32}{8813071}{30566940}
\pgfsyspdfmark {pgfid35}{39492954}{30579228}
\pgfsyspdfmark {pgfid36}{41344346}{30355314}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Real Data}{15}{subsection.3.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ finish this}{15}{section*.55}}
\pgfsyspdfmark {pgfid37}{18845552}{26736274}
\pgfsyspdfmark {pgfid40}{39492954}{26748562}
\pgfsyspdfmark {pgfid41}{41344346}{26524648}
\citation{Schmidhuber}
\@writefile{toc}{\contentsline {section}{\numberline {4}Implementation}{16}{section.4}}
\newlabel{Implementation}{{4}{16}{Implementation}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Process Overview}{16}{subsection.4.1}}
\newlabel{ProcessOverview}{{4.1}{16}{Process Overview}{subsection.4.1}{}}
\newlabel{imp_overview}{{4.1}{16}{Process Overview}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Feedforward Neural Networks}{16}{subsection.4.2}}
\newlabel{imp_ffn}{{4.2}{16}{Feedforward Neural Networks}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Notation and Network Representation}{16}{subsubsection.4.2.1}}
\newlabel{imp_ffn_functions}{{4.2.1}{16}{Notation and Network Representation}{subsubsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Activation Functions}{16}{subsubsection.4.2.2}}
\@writefile{toc}{\contentsline {subparagraph}{Sigmoid}{16}{section*.56}}
\newlabel{func_sigmoid}{{14}{16}{Sigmoid}{equation.4.14}{}}
\@writefile{toc}{\contentsline {subparagraph}{ReLU}{17}{section*.57}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{blue}{}{blue!25}{\leavevmode {\color  {blue!25}o}}\ needs reference section}{17}{section*.58}}
\pgfsyspdfmark {pgfid42}{21191135}{51580827}
\pgfsyspdfmark {pgfid45}{39492954}{51593115}
\pgfsyspdfmark {pgfid46}{41344346}{51369201}
\newlabel{func_relu}{{15}{17}{ReLU}{equation.4.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3}Backpropagation}{17}{subsubsection.4.2.3}}
\newlabel{imp_backprop}{{4.2.3}{17}{Backpropagation}{subsubsection.4.2.3}{}}
\newlabel{function_MSE}{{16}{17}{Backpropagation}{equation.4.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4}Gradient Descent Algorithms}{17}{subsubsection.4.2.4}}
\newlabel{imp_sgd}{{4.2.4}{17}{Gradient Descent Algorithms}{subsubsection.4.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5}Gradient Descent Improvements}{18}{subsubsection.4.2.5}}
\newlabel{imp_gradientimprovements}{{4.2.5}{18}{Gradient Descent Improvements}{subsubsection.4.2.5}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ write this section}{18}{section*.59}}
\pgfsyspdfmark {pgfid47}{4844489}{49584711}
\pgfsyspdfmark {pgfid50}{39492954}{49596999}
\pgfsyspdfmark {pgfid51}{41344346}{49373085}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Restricted Boltzmann Machines}{18}{subsection.4.3}}
\newlabel{imp_rbm}{{4.3}{18}{Restricted Boltzmann Machines}{subsection.4.3}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ add Hopfield 1982 ref}{18}{section*.60}}
\pgfsyspdfmark {pgfid52}{23960708}{39462589}
\pgfsyspdfmark {pgfid55}{39492954}{39474877}
\pgfsyspdfmark {pgfid56}{41344346}{39250963}
\newlabel{func_rbmenergy}{{20}{18}{Restricted Boltzmann Machines}{equation.4.20}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ add hinton reference TR guide}{18}{section*.61}}
\pgfsyspdfmark {pgfid57}{4247378}{35246438}
\pgfsyspdfmark {pgfid60}{39492954}{35258726}
\pgfsyspdfmark {pgfid61}{41344346}{35034812}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Contrastive Divergence}{18}{subsubsection.4.3.1}}
\newlabel{imp_CD}{{4.3.1}{18}{Contrastive Divergence}{subsubsection.4.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}CD-1 and SGD}{19}{subsubsection.4.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Stacked Autoencoders}{19}{subsection.4.4}}
\newlabel{imp_SAE}{{4.4}{19}{Stacked Autoencoders}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Sigmoid based Greedy Layerwise SAE Training}{19}{subsubsection.4.4.1}}
\newlabel{imp_sigmoidsae}{{4.4.1}{19}{Sigmoid based Greedy Layerwise SAE Training}{subsubsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}ReLU based SAE Training}{19}{subsubsection.4.4.2}}
\newlabel{imp_relusae}{{4.4.2}{19}{ReLU based SAE Training}{subsubsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Denoising Autoencoders}{20}{subsubsection.4.4.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ decide on this}{20}{section*.62}}
\pgfsyspdfmark {pgfid62}{34294787}{50371143}
\pgfsyspdfmark {pgfid65}{39492954}{50383431}
\pgfsyspdfmark {pgfid66}{41344346}{50159517}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Variance Based Weight Initializations}{20}{subsection.4.5}}
\newlabel{imp_weights}{{4.5}{20}{Variance Based Weight Initializations}{subsection.4.5}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ add LR reference here}{20}{section*.63}}
\pgfsyspdfmark {pgfid67}{10505521}{47326909}
\pgfsyspdfmark {pgfid70}{39492954}{47339197}
\pgfsyspdfmark {pgfid71}{41344346}{47115283}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ add ref}{20}{section*.64}}
\pgfsyspdfmark {pgfid72}{27987318}{42608317}
\pgfsyspdfmark {pgfid75}{39492954}{42620605}
\pgfsyspdfmark {pgfid76}{41344346}{42396691}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ add ref}{20}{section*.65}}
\pgfsyspdfmark {pgfid77}{33086068}{26557515}
\pgfsyspdfmark {pgfid80}{39492954}{26569803}
\pgfsyspdfmark {pgfid81}{41344346}{26345889}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ add ref}{20}{section*.66}}
\pgfsyspdfmark {pgfid82}{25273545}{19293850}
\pgfsyspdfmark {pgfid85}{39492954}{19306138}
\pgfsyspdfmark {pgfid86}{41344346}{19082224}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Trading Algorithms}{20}{subsection.4.6}}
\newlabel{imp_tradingstrat}{{4.6}{20}{Trading Algorithms}{subsection.4.6}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ }{20}{section*.67}}
\pgfsyspdfmark {pgfid87}{5152146}{13317959}
\pgfsyspdfmark {pgfid90}{39492954}{13330247}
\pgfsyspdfmark {pgfid91}{41344346}{13106333}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}CSCV \& PBO}{20}{subsection.4.7}}
\newlabel{imp_cscv}{{4.7}{20}{CSCV \& PBO}{subsection.4.7}{}}
\newlabel{eq:PBO1}{{33}{20}{CSCV \& PBO}{equation.4.33}{}}
\citation{BailyPBO}
\newlabel{eq:PBO2}{{34}{21}{CSCV \& PBO}{equation.4.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Performance Assessment}{21}{subsection.4.8}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ }{21}{section*.68}}
\pgfsyspdfmark {pgfid92}{7618854}{3940985}
\pgfsyspdfmark {pgfid95}{39492954}{3953273}
\pgfsyspdfmark {pgfid96}{41344346}{3729359}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Full Process Implementation}{22}{subsection.4.9}}
\newlabel{imp_fullprocess}{{4.9}{22}{Full Process Implementation}{subsection.4.9}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ update with decided windows}{22}{section*.69}}
\pgfsyspdfmark {pgfid97}{32593572}{46570055}
\pgfsyspdfmark {pgfid100}{39492954}{46582343}
\pgfsyspdfmark {pgfid101}{41344346}{46358429}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ update with decided windows}{22}{section*.70}}
\pgfsyspdfmark {pgfid102}{29709984}{45521479}
\pgfsyspdfmark {pgfid105}{39492954}{45149655}
\pgfsyspdfmark {pgfid106}{41344346}{44925741}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ update with decided split}{22}{section*.71}}
\pgfsyspdfmark {pgfid107}{35884944}{42113607}
\pgfsyspdfmark {pgfid110}{39492954}{42125895}
\pgfsyspdfmark {pgfid111}{41344346}{41901981}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results}{23}{section.5}}
\newlabel{Results}{{5}{23}{Results}{section.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Working Notes}{23}{section*.72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Money Management Strategy and Returns}{23}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results for Synthetic Data}{24}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Dataset Generation}{24}{subsubsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Price Points\relax }}{25}{figure.caption.73}}
\newlabel{figure-synthetic-prices}{{29}{25}{Price Points\relax }{figure.caption.73}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}SAE Network and Results}{25}{subsubsection.5.2.2}}
\newlabel{results_synthetic_sae}{{5.2.2}{25}{SAE Network and Results}{subsubsection.5.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.3}Predictive FFN Network and Results}{25}{subsubsection.5.2.3}}
\@writefile{toc}{\contentsline {paragraph}{SAE Results}{25}{section*.74}}
\@writefile{toc}{\contentsline {paragraph}{Layer Size \& SGD Learning Rate Results}{25}{section*.75}}
\@writefile{toc}{\contentsline {paragraph}{OGD Learning Rate Results}{25}{section*.76}}
\@writefile{toc}{\contentsline {paragraph}{Prediction Plots}{25}{section*.77}}
\@writefile{toc}{\contentsline {paragraph}{CSCV Plots}{25}{section*.78}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Results for Real Data}{25}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{26}{section.6}}
\newlabel{Conclusion}{{6}{26}{Conclusions}{section.6}{}}
\bibcite{Albers}{1}
\bibcite{Aparicio}{2}
\bibcite{Arthur}{3}
\bibcite{BailyPBO}{4}
\bibcite{BaileyBTL}{5}
\bibcite{BaileySharpe}{6}
\bibcite{Bakiri}{7}
\bibcite{Bao}{8}
\bibcite{Bartlett}{9}
\bibcite{Bengio1}{10}
\bibcite{Bengio2}{11}
\bibcite{Bengio3}{12}
\bibcite{Bottou}{13}
\bibcite{Bottou2}{14}
\bibcite{Ciresan}{15}
\bibcite{Chu}{16}
\bibcite{Chung}{17}
\bibcite{Crutchfield}{18}
\bibcite{Dauphin}{19}
\@writefile{toc}{\contentsline {section}{\numberline {7}References}{27}{section.7}}
\bibcite{Devarakonda}{20}
\bibcite{Donoho}{21}
\bibcite{Duchi}{22}
\bibcite{Erhan}{23}
\bibcite{Fama}{24}
\bibcite{Fan1}{25}
\bibcite{Fan2}{26}
\bibcite{Ge}{27}
\bibcite{Goodfellow}{28}
\bibcite{Glorot}{29}
\bibcite{Glorot2}{30}
\bibcite{Griffioen}{31}
\bibcite{Hansen}{32}
\bibcite{Harvey}{33}
\bibcite{Hawkins}{34}
\bibcite{Hinton1}{35}
\bibcite{Hinton2}{36}
\bibcite{Hinton3}{37}
\bibcite{Hinton4}{38}
\bibcite{HLZ}{39}
\bibcite{Hochreiter}{40}
\bibcite{Hornik}{41}
\bibcite{Hsu}{42}
\bibcite{Ivakhnenko}{43}
\bibcite{ImageNet}{44}
\bibcite{Ioannidis}{45}
\bibcite{Johnson}{46}
\bibcite{Kahn}{47}
\bibcite{Knerr}{48}
\bibcite{Langford}{49}
\bibcite{Langkvist}{50}
\bibcite{LeCun}{51}
\bibcite{LeCun2}{52}
\bibcite{LeCun3}{53}
\bibcite{LeCun4}{54}
\bibcite{LeRoux}{55}
\bibcite{Liu}{56}
\bibcite{Lo}{57}
\bibcite{Lv}{58}
\bibcite{Mahajan}{59}
\bibcite{McLean}{60}
\bibcite{Minksy}{61}
\bibcite{Murphy}{62}
\bibcite{Pascanu}{63}
\bibcite{Prado}{64}
\bibcite{Povey}{65}
\bibcite{Ranzato1}{66}
\bibcite{Rumelhart}{67}
\bibcite{Schaefer}{68}
\bibcite{Schmidhuber}{69}
\bibcite{Schorfheide}{70}
\bibcite{Schwager}{71}
\bibcite{Sermanet}{72}
\bibcite{Shalev}{73}
\bibcite{Siegelmann}{74}
\bibcite{Skabar}{75}
\bibcite{Takeuchi}{76}
\bibcite{Troiano}{77}
\bibcite{Tseng}{78}
\bibcite{Vincent}{79}
\bibcite{Wan}{80}
\bibcite{Wang}{81}
\bibcite{Wang2}{82}
\bibcite{WaveNet}{83}
\bibcite{Weiss}{84}
\bibcite{Werbos}{85}
\bibcite{Werbos2}{86}
\bibcite{Wu}{87}
\bibcite{Yin}{88}
\bibcite{Zeiler}{89}
\bibcite{Zinkevich}{90}
\bibcite{Zhao}{91}
\bibcite{Zhang}{92}
\bibcite{Zhou}{93}
