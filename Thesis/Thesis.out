\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{LiteratureReview}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Technical Analysis}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Neural Networks}{section.2}% 4
\BOOKMARK [3][-]{subsubsection.2.2.1}{Training and Backpropagation}{subsection.2.2}% 5
\BOOKMARK [3][-]{subsubsection.2.2.2}{Activation Functions}{subsection.2.2}% 6
\BOOKMARK [3][-]{subsubsection.2.2.3}{Deep Learning}{subsection.2.2}% 7
\BOOKMARK [3][-]{subsubsection.2.2.4}{Backpropagation Improvements}{subsection.2.2}% 8
\BOOKMARK [2][-]{subsection.2.3}{Stacked Autoencoders}{section.2}% 9
\BOOKMARK [3][-]{subsubsection.2.3.1}{High Dimensional Data Reduction}{subsection.2.3}% 10
\BOOKMARK [3][-]{subsubsection.2.3.2}{Deep Belief Networks}{subsection.2.3}% 11
\BOOKMARK [3][-]{subsubsection.2.3.3}{Stacked Denoising Autoencoders}{subsection.2.3}% 12
\BOOKMARK [3][-]{subsubsection.2.3.4}{Pre-training}{subsection.2.3}% 13
\BOOKMARK [3][-]{subsubsection.2.3.5}{Time Series Applications}{subsection.2.3}% 14
\BOOKMARK [3][-]{subsubsection.2.3.6}{Financial Applications}{subsection.2.3}% 15
\BOOKMARK [2][-]{subsection.2.4}{Data Segmentation}{section.2}% 16
\BOOKMARK [2][-]{subsection.2.5}{Online Learning Algorithms and Gradient Descent}{section.2}% 17
\BOOKMARK [2][-]{subsection.2.6}{Backtesting and Model Validation}{section.2}% 18
\BOOKMARK [3][-]{subsubsection.2.6.1}{Testing Methodologies}{subsection.2.6}% 19
\BOOKMARK [3][-]{subsubsection.2.6.2}{Test Data Length}{subsection.2.6}% 20
\BOOKMARK [3][-]{subsubsection.2.6.3}{Sharpe Ratio}{subsection.2.6}% 21
\BOOKMARK [1][-]{section.3}{Data}{}% 22
\BOOKMARK [2][-]{subsection.3.1}{Data Processing}{section.3}% 23
\BOOKMARK [2][-]{subsection.3.2}{Data Scaling}{section.3}% 24
\BOOKMARK [2][-]{subsection.3.3}{Synthetic Data}{section.3}% 25
\BOOKMARK [2][-]{subsection.3.4}{Real Data}{section.3}% 26
\BOOKMARK [1][-]{section.4}{Implementation}{}% 27
\BOOKMARK [2][-]{subsection.4.1}{Process Overview}{section.4}% 28
\BOOKMARK [2][-]{subsection.4.2}{Feedforward Neural Networks}{section.4}% 29
\BOOKMARK [3][-]{subsubsection.4.2.1}{Notation and Network Representation}{subsection.4.2}% 30
\BOOKMARK [3][-]{subsubsection.4.2.2}{Activation Functions}{subsection.4.2}% 31
\BOOKMARK [3][-]{subsubsection.4.2.3}{Backpropagation}{subsection.4.2}% 32
\BOOKMARK [3][-]{subsubsection.4.2.4}{Gradient Descent Algorithms}{subsection.4.2}% 33
\BOOKMARK [3][-]{subsubsection.4.2.5}{Gradient Descent Improvements}{subsection.4.2}% 34
\BOOKMARK [2][-]{subsection.4.3}{Restricted Boltzmann Machines}{section.4}% 35
\BOOKMARK [3][-]{subsubsection.4.3.1}{Contrastive Divergence}{subsection.4.3}% 36
\BOOKMARK [3][-]{subsubsection.4.3.2}{CD-1 and SGD}{subsection.4.3}% 37
\BOOKMARK [2][-]{subsection.4.4}{Stacked Autoencoders}{section.4}% 38
\BOOKMARK [3][-]{subsubsection.4.4.1}{Sigmoid based Greedy Layerwise SAE Training}{subsection.4.4}% 39
\BOOKMARK [3][-]{subsubsection.4.4.2}{ReLU based SAE Training}{subsection.4.4}% 40
\BOOKMARK [3][-]{subsubsection.4.4.3}{Denoising Autoencoders}{subsection.4.4}% 41
\BOOKMARK [2][-]{subsection.4.5}{Variance Based Weight Initializations}{section.4}% 42
\BOOKMARK [2][-]{subsection.4.6}{Trading Algorithms}{section.4}% 43
\BOOKMARK [2][-]{subsection.4.7}{CSCV \046 PBO}{section.4}% 44
\BOOKMARK [2][-]{subsection.4.8}{Performance Assessment}{section.4}% 45
\BOOKMARK [2][-]{subsection.4.9}{Full Process Implementation}{section.4}% 46
\BOOKMARK [1][-]{section.5}{Results}{}% 47
\BOOKMARK [2][-]{subsection.5.1}{Search Methods and Parameters}{section.5}% 48
\BOOKMARK [2][-]{subsection.5.2}{Results for Synthetic Data}{section.5}% 49
\BOOKMARK [3][-]{subsubsection.5.2.1}{Dataset Generation}{subsection.5.2}% 50
\BOOKMARK [3][-]{subsubsection.5.2.2}{SAE Network and Results}{subsection.5.2}% 51
\BOOKMARK [2][-]{subsection.5.3}{Results for Real Data}{section.5}% 52
\BOOKMARK [1][-]{section.6}{Conclusions}{}% 53
\BOOKMARK [1][-]{section.7}{References}{}% 54
